{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# text models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# for handling imbalanced data\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import pickle\n",
    "\n",
    "# for load data\n",
    "# from glob import glob\n",
    "import os # for file handling\n",
    "import glob # for file handling\n",
    "import shutil # for moving files\n",
    "\n",
    "# scientific computing library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# for data preprocessing\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# for image preprocessing\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# for model building\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.layers import Layer, DepthwiseConv2D, Conv2D, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Add, GlobalAveragePooling2D, Dense, Input, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from keras import metrics\n",
    "import tensorflow_hub as hub\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'G:\\\\HSUHK\\\\COM6003\\\\project\\\\archive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "INPUT_SHAPE = (256, 256, 3)\n",
    "IMG_SIZE = (256, 256)\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50\n",
    "SEED = 11\n",
    "keras.utils.set_random_seed(SEED)\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self, data):\n",
    "        self.data = pd.DataFrame(data)\n",
    "        \n",
    "    def clean_text(self):\n",
    "        self.data.drop(columns=['patient_id', 'lesion_id', 'biopsed'], inplace=True)\n",
    "        self.data['label'] = self.data['diagnostic']\n",
    "        self.data.drop(columns='diagnostic', inplace=True)\n",
    "        self.data.replace({'UNK':-1, 'NaN':-1, np.nan:-1, 'FALSE': 'False', 'TRUE': 'True'}, inplace=True)\n",
    "\n",
    "    def encode_text(self):\n",
    "        binary_column_name = ['smoke', 'drink', 'pesticide', 'gender', 'skin_cancer_history', \n",
    "                              'cancer_history', 'has_piped_water', 'has_sewage_system', \n",
    "                              'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation']\n",
    "        self.convert_to_binary(binary_column_name)\n",
    "        self.convert_to_integer('background_father', {'AUSTRIA':0, 'BRASIL':1, 'BRAZIL':2, 'CZECH':3,\n",
    "                                                             'GERMANY':4, 'ISRAEL':5, 'ITALY':6, 'NETHERLANDS':7,\n",
    "                                                                'POLAND':8, 'POMERANIA':9, 'PORTUGAL':10, 'SPAIN':11})\n",
    "        self.convert_to_integer('background_mother', {'BRAZIL':0, 'FRANCE':1, 'GERMANY':2, 'ITALY':3,\n",
    "                                                                'NETHERLANDS':4, 'NORWAY':5, 'POLAND':6, 'POMERANIA':7,\n",
    "                                                                'PORTUGAL':8, 'SPAIN':9})\n",
    "        self.convert_to_integer('region', {'ABDOMEN':0, 'ARM':1, 'BACK':2, 'CHEST':3, \n",
    "                                                                     'EAR':4, 'FACE':5, 'FOOT':6, 'FOREARM':7, \n",
    "                                                                     'HAND':8, 'LIP':9, 'NECK':10, 'NOSE':11, \n",
    "                                                                     'SCALP':12, 'THIGH':13})\n",
    "        self.convert_to_integer('label', {'ACK':0, 'BCC':1, 'MEL':2, 'NEV':3, 'SCC':4, 'SEK':5})\n",
    "    \n",
    "    def convert_to_binary(self, column_name):\n",
    "        for i in column_name:\n",
    "            if i =='gender':\n",
    "                self.data[i] = self.data[i].replace({'FEMALE':0, 'MALE':1}).astype(int)\n",
    "            else:\n",
    "                self.data[i] = self.data[i].replace({'False': 0, 'True': 1}).astype(int)\n",
    "\n",
    "    def convert_to_integer(self, column_name, mapping):\n",
    "        self.data[column_name] = self.data[column_name].replace(mapping).astype(int)\n",
    "\n",
    "\n",
    "    def text_preprocess(self):\n",
    "        self.clean_text()\n",
    "        self.encode_text()\n",
    "        self.convert_image_path()\n",
    "        return self.data\n",
    "    \n",
    "    def get_image_path(self):\n",
    "        image_path = []\n",
    "        for root, dirs, files in os.walk(data_path):\n",
    "            for file in files:\n",
    "                if file.endswith('.png'):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    image_path.append(os.path.abspath(file_path))\n",
    "        return image_path\n",
    "    \n",
    "    def convert_image_path(self):\n",
    "        pattern = {}\n",
    "        for path in self.get_image_path():\n",
    "            if os.path.basename(path) in self.data['img_id'].values:\n",
    "                pattern[os.path.basename(path)] = path\n",
    "        self.data['img_id'] = self.data['img_id'].replace(pattern)\n",
    "\n",
    "    \n",
    "class ImagePreprocessor:\n",
    "    def __init__(self, data, image_size=(256, 256), batch_size=32):\n",
    "        self.data = pd.DataFrame(data)\n",
    "        self.image_path = self.data['img_id']\n",
    "        self.labels = self.data['label']\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def load_image(self):\n",
    "        image = Image.open(self.image_path)\n",
    "        image = image.resize(IMG_SIZE)\n",
    "        image = np.array(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       G:\\HSUHK\\COM6003\\project\\archive\\Index6\\val\\PA...\n",
       "1       G:\\HSUHK\\COM6003\\project\\archive\\imgs_part_1\\i...\n",
       "2       G:\\HSUHK\\COM6003\\project\\archive\\imgs_part_3\\i...\n",
       "3       G:\\HSUHK\\COM6003\\project\\archive\\Index2\\train\\...\n",
       "4       G:\\HSUHK\\COM6003\\project\\archive\\Index6\\val\\PA...\n",
       "                              ...                        \n",
       "2293    G:\\HSUHK\\COM6003\\project\\archive\\imgs_part_3\\i...\n",
       "2294    G:\\HSUHK\\COM6003\\project\\archive\\imgs_part_1\\i...\n",
       "2295    G:\\HSUHK\\COM6003\\project\\archive\\imgs_part_3\\i...\n",
       "2296    G:\\HSUHK\\COM6003\\project\\archive\\Index6\\train\\...\n",
       "2297    G:\\HSUHK\\COM6003\\project\\archive\\imgs_part_3\\i...\n",
       "Name: img_id, Length: 2298, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(data_path+'\\\\metadata.csv')\n",
    "df = TextPreprocessor(metadata).text_preprocess()\n",
    "df['img_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "        def split_data(self):\n",
    "        self.train, self.test = train_test_split(self.metadata, test_size=0.2, random_state=42)\n",
    "        self.train, self.val = train_test_split(self.train, test_size=0.2, random_state=42)\n",
    "        \n",
    "    \n",
    "    def balance_data(self):\n",
    "        class_count = Counter(self.train['label'])\n",
    "        min_class_count = min(class_count.values())\n",
    "\n",
    "        over_sample_strategy = {label: 2*min_class_count for label in class_count.keys() if class_count[label] <= (2 * min_class_count)}\n",
    "        under_sample_strategy = {label: 2* min_class_count for label in class_count.keys() if class_count[label] > (2 * min_class_count)}\n",
    "\n",
    "        pipe = make_pipeline(\n",
    "        SMOTE(sampling_strategy=over_sample_strategy),\n",
    "        NearMiss(sampling_strategy=under_sample_strategy)\n",
    "    )\n",
    "        \n",
    "        self.x_train, self.y_train = pipe.fit_resample(self.x_train, self.y_train)\n",
    "\n",
    "    def create_datagen(self, img_size=(256, 256), batch_size=16, channels=3):\n",
    "        def img_preprocessing(image, label):\n",
    "            image = tf.io.read_file(image)\n",
    "            image = tf.image.decode_png(image, channels=channels)\n",
    "            image = tf.image.resize(image, img_size)\n",
    "            image = tf.cast(image, tf.float32) / 255.0\n",
    "            return image, label\n",
    "        \n",
    "        def augmentation(image, label):\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "            image = tf.image.random_flip_up_down(image)\n",
    "            image = tf.image.random_brightness(image, 0.2)\n",
    "            image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "            image = tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "            return image, label\n",
    "        \n",
    "        def create_dataset(data, augment=True):\n",
    "            loader = tf.data.Dataset.from_tensor_slices((data))\n",
    "            if augment:\n",
    "                dataset = (loader.map(img_preprocessing, num_parallel_calls=AUTO)\n",
    "                                .map(augmentation, num_parallel_calls=AUTO)\n",
    "                                .batch(batch_size)\n",
    "                                .shuffle(batch_size * 10)\n",
    "                                .prefetch(AUTO).repeat())\n",
    "            else:\n",
    "                dataset = (loader.map(img_preprocessing, num_parallel_calls=AUTO)\n",
    "                                .batch(batch_size)\n",
    "                                .prefetch(AUTO))\n",
    "            \n",
    "            return dataset\n",
    "\n",
    "        train_dataset = create_dataset(self.train, self.train['label'], augment=True)\n",
    "        val_dataset = create_dataset(self.val, self.val['label'])\n",
    "        test_dataset = create_dataset(self.test, self.test['label'])\n",
    "        \n",
    "        return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "    def preprocess(self):\n",
    "        self.clean_data()\n",
    "        self.impute_data()\n",
    "        # self.split_data()\n",
    "        # self.balance_data()\n",
    "        return self.train, self.val, self.test\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datagen(x_train, y_train, x_val, y_val, x_test, y_test, img_size=(256, 256), batch_size=16, channels=3):\n",
    "    \"\"\" Create data generators for training, validation, and testing datasets. \"\"\"\n",
    "    def img_preprocessing(img, label):\n",
    "        \"\"\" Image preprocessing function \"\"\"\n",
    "        img = tf.io.read_file(img)  # Read the image file\n",
    "        img = tf.image.decode_png(img, channels=channels)  # Decode the PNG image\n",
    "        img = tf.image.resize(img, img_size)  # Resize the image\n",
    "        img = tf.cast(img, tf.float32) / 255.0  # Normalize pixel values to [0, 1] range\n",
    "        return img, label\n",
    "\n",
    "    def augmentation(image, label):\n",
    "        \"\"\" Data augmentation function \"\"\"\n",
    "        image = tf.image.random_flip_left_right(image)  # Randomly flip the image horizontally\n",
    "        image = tf.image.random_flip_up_down(image)  # Randomly flip the image vertically\n",
    "        image = tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)) # Randomly rotate the image\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)  # Randomly adjust brightness\n",
    "        image = tf.image.random_contrast(image, lower=0.8, upper=1.2)  # Randomly adjust contrast\n",
    "        return image, label\n",
    "\n",
    "    def create_dataset(x, y, augment=False):\n",
    "    # Create dataset loaders and tf.datasets\n",
    "        loader = tf.data.Dataset.from_tensor_slices((x.iloc[:,0], y))\n",
    "        if augment:\n",
    "            dataset = (loader.map(img_preprocessing, num_parallel_calls=AUTO)  # Apply image preprocessing function)\n",
    "                            .map(augmentation, num_parallel_calls=AUTO)  # Apply data augmentation function\n",
    "                            .batch(batch_size)  # Batch the data\n",
    "                            .shuffle(batch_size * 10)  # Shuffle the dataset\n",
    "                            .prefetch(AUTO).repeat())  # Prefetch data for performance\n",
    "        else:\n",
    "            dataset = (loader.map(img_preprocessing, num_parallel_calls=AUTO)\n",
    "                            .batch(batch_size) # Batch the data\n",
    "                            .prefetch(AUTO)) # Prefetch data for performance\n",
    "            \n",
    "        return dataset\n",
    "\n",
    "    train_dataset = create_dataset(x_train, y_train, augment=True)\n",
    "    val_dataset = create_dataset(x_val, y_val)\n",
    "    test_dataset = create_dataset(x_test, y_test)\n",
    "    \n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "dataprocessing = DataProcessing()\n",
    "train, val, test = dataprocessing.preprocess()\n",
    "print(train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
